{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import plotly.express as px\n",
    "pd.options.display.max_columns = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starters_train = pd.read_csv('data/fangraphs/pitchers/starters/pitchers_sp_19_21.csv')\n",
    "starters_test = pd.read_csv('data/fangraphs/pitchers/starters/pitchers_sp_22.csv')\n",
    "\n",
    "starters_train = starters_train.fillna(0)\n",
    "starters_test = starters_test.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starters_train.columns\n",
    "\n",
    "starter_features = ['K/9_x','BB/9_x','HR/9_x','BABIP_x','LOB%_x','GB%_x','HR/FB_x','vFA (pi)','ERA_x','xERA','FIP_x','xFIP_x','WAR','CG','ShO','SV_y','HLD','BS','IP_y','TBF','H','R','ER','HR','BB','IBB','HBP','WP','BK','K%','BB%','K-BB%','AVG',\t'ERA-',\t'FIP-', 'xFIP-', 'E-F',\t'SIERA', 'BABIP', 'GB/FB', 'LD%','FB%_x','IFFB%','RS','RS/9','Balls','Strikes','Pitches','Pull%','Cent%','Oppo%','Soft%','Med%','Hard%','O-Swing%','Z-Swing%','Swing%','O-Contact%','Z-Contact%','Contact%','Zone%','F-Strike%','SwStr%','CStr%','CSW%','FBv','SL%','SLv','CT%','CTv','CB%','CBv','CH%','CHv','SF%','SFv','KN%','KNv','XX%','wFB','wSL','wCT','wCB','wCH','wSF','wKN','wFB/C','wSL/C','wCT/C','wCB/C','wCH/C','wSF/C','wKN/C']\n",
    "starter_targets = ['W_x', 'SO', 'ERA','WHIP']\n",
    "starters_train[starter_features] = starters_train[starter_features].replace({'%':''}, regex=True)\n",
    "starters_test[starter_features] = starters_test[starter_features].replace({'%':''}, regex=True)\n",
    "starters_test_dropped_cols = starters_test.drop(starter_targets,axis=1)\n",
    "\n",
    "# Not used for now: 'L_x','SV_x','G_x','GS_x','IP_x',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "maes = []\n",
    "for target in starter_targets:\n",
    "    rf.fit(starters_train[starter_features], starters_train[target])\n",
    "    # Make predictions on the test set\n",
    "    predictions = rf.predict(starters_test_dropped_cols[starter_features])\n",
    "    predict_string = \"Predicted_\"+str(target)\n",
    "    # Assign the predictions to the players in the test set\n",
    "    starters_test_dropped_cols[predict_string] = predictions\n",
    "    mae = mean_absolute_error(predictions, starters_test[target])\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starters_test_dropped_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vs_actual_ws = px.scatter(starters_test_dropped_cols, x='W_y', y='Predicted_W_x', title='Predicted vs Actual Wins', hover_data=['Name','Team'])\n",
    "predicted_vs_actual_ws.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starters_ws_vs_ks = px.scatter(starters_test_dropped_cols, x='Predicted_SO', y='Predicted_W_x', color='Predicted_ERA', title='Predicted Strikeouts vs Wins 2022', hover_data=['Name', 'Team'])\n",
    "plot_filename='plots/predicted_starters_ws_vs_ks.html'\n",
    "starters_ws_vs_ks.write_html(plot_filename)\n",
    "starters_ws_vs_ks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strikeouts Model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load the data into a pandas dataframe\n",
    "df = pd.read_csv(\"fantasy_baseball_data.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "# ... (fill in missing values, handle outliers, etc.)\n",
    "\n",
    "# Select features for the model\n",
    "features = [\"AVG\", \"HR\", \"RBI\", \"SB\", \"OPS\", \"Games\", \"AtBats\", \"Hits\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df[df[\"Year\"] != 2022]\n",
    "test_data = df[df[\"Year\"] == 2022]\n",
    "\n",
    "# Train a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(train_data[features], train_data[\"FantasyValue\"])\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = rf.predict(test_data[features])\n",
    "\n",
    "# Assign the predictions to the players in the test set\n",
    "test_data[\"PredictedFantasyValue\"] = predictions\n",
    "\n",
    "# Sort the players by their predicted fantasy value\n",
    "sorted_data = test_data.sort_values(\"PredictedFantasyValue\", ascending=False)\n",
    "\n",
    "# Display the top 10 players with the highest predicted fantasy value\n",
    "print(sorted_data[[\"Player\", \"PredictedFantasyValue\"]].head(10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reliever Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relievers_train = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_19_21.csv')\n",
    "relievers_test = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_22.csv')\n",
    "\n",
    "relievers_train = relievers_train.fillna(0)\n",
    "relievers_test = relievers_test.fillna(0)\n",
    "\n",
    "\n",
    "relievers_train.columns\n",
    "\n",
    "relievers_features = ['K/9_x','BB/9_x','HR/9_x','BABIP_x','LOB%_x','GB%_x','HR/FB_x','vFA (pi)','ERA_x','xERA','FIP_x','xFIP_x','WAR','CG','ShO','BS','IP_y','TBF','H','R','ER','HR','BB','IBB','HBP','WP','BK','K%','BB%','K-BB%','AVG',\t'ERA-',\t'FIP-', 'xFIP-', 'E-F',\t'SIERA', 'BABIP', 'GB/FB', 'LD%','FB%_x','IFFB%','RS','RS/9','Balls','Strikes','Pitches','Pull%','Cent%','Oppo%','Soft%','Med%','Hard%','O-Swing%','Z-Swing%','Swing%','O-Contact%','Z-Contact%','Contact%','Zone%','F-Strike%','SwStr%','CStr%','CSW%','FBv','SL%','SLv','CT%','CTv','CB%','CBv','CH%','CHv','SF%','SFv','KN%','KNv','XX%','wFB','wSL','wCT','wCB','wCH','wSF','wKN','wFB/C','wSL/C','wCT/C','wCB/C','wCH/C','wSF/C','wKN/C']\n",
    "relievers_targets = ['W_x', 'SV_y', 'HLD', 'SO', 'ERA', 'WHIP']\n",
    "relievers_train[relievers_features] = relievers_train[relievers_features].replace({'%':''}, regex=True)\n",
    "relievers_test[relievers_features] = relievers_test[relievers_features].replace({'%':''}, regex=True)\n",
    "relievers_test_dropped_cols = relievers_test.drop(relievers_targets,axis=1)\n",
    "\n",
    "# Not used for now: 'L_x','SV_x','G_x','GS_x','IP_x',\n",
    "\n",
    "# Train a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "maes = []\n",
    "for target in relievers_targets:\n",
    "    rf.fit(relievers_train[relievers_features], relievers_train[target])\n",
    "    # Make predictions on the test set\n",
    "    predictions = rf.predict(relievers_test_dropped_cols[relievers_features])\n",
    "    predict_string = \"Predicted_\"+str(target)\n",
    "    # Assign the predictions to the players in the test set\n",
    "    relievers_test_dropped_cols[predict_string] = predictions\n",
    "    mae = mean_absolute_error(predictions, relievers_test[target])\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relievers_vs_actual_saves = px.scatter(relievers_test_dropped_cols, x=relievers_test['SV_x'], y=relievers_test_dropped_cols['Predicted_SV_y'], title='Relievers Predicted vs Actual Saves 2022', hover_data=['Name', 'Team'])\n",
    "plot_filename='plots/relievers_predicted_vs actual_saves.html'\n",
    "relievers_vs_actual_saves.write_html(plot_filename)\n",
    "relievers_vs_actual_saves.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relievers_vs_actual_saves = px.scatter(relievers_test_dropped_cols, x=relievers_test['SO'], y=relievers_test_dropped_cols['Predicted_SO'], title='Relievers Predicted vs Actual Strikeouts 2022', hover_data=['Name', 'Team'])\n",
    "plot_filename='plots/relievers_predicted_vs_actual_saves.html'\n",
    "relievers_vs_actual_saves.write_html(plot_filename)\n",
    "relievers_vs_actual_saves.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relievers_ws_vs_ks = px.scatter(relievers_test_dropped_cols, x='Predicted_SO', y='Predicted_SV_y', color='Predicted_ERA', title='Predicted Strikeouts vs Saves 2022', hover_data=['Name', 'Team'])\n",
    "plot_filename='plots/relievers_predicted_svs_vs_ks.html'\n",
    "relievers_ws_vs_ks.write_html(plot_filename)\n",
    "relievers_ws_vs_ks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relievers_ws_vs_ks = px.scatter(relievers_test_dropped_cols, x='Predicted_SO', y='Predicted_HLD', color='Predicted_ERA', title='Predicted Strikeouts vs Holds 2022', hover_data=['Name', 'Team'])\n",
    "plot_filename='plots/predicted_relievers_hlds_vs_ks.html'\n",
    "relievers_ws_vs_ks.write_html(plot_filename)\n",
    "relievers_ws_vs_ks.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection Building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_starting_pitchers(model_obj, year_to_project, train_dataset, test_dataset):\n",
    "\n",
    "    # Preprocess the data and select features for the model\n",
    "\n",
    "    train_dataset = train_dataset.fillna(0)\n",
    "    test_dataset = test_dataset.fillna(0)\n",
    "\n",
    "    train_dataset['Sum_of_ERA_WHIP'] = train_dataset['ERA_x'] + train_dataset['WHIP']\n",
    "    test_dataset['Sum_of_ERA_WHIP'] = test_dataset['ERA_x'] + test_dataset['WHIP']\n",
    "\n",
    "    chosen_cols = ['K/9_x','BB/9_x','HR/9_x','BABIP_x','LOB%_x','GB%_x','HR/FB_x','vFA (pi)',\n",
    "                   'FIP_x','xFIP_x','CG','ShO','BS','K%','BB%','K-BB%','AVG','FIP-', 'xFIP-', \n",
    "                   'E-F',\t'BABIP', 'GB/FB', 'LD%','FB%_x','IFFB%','RS/9','Pull%','Cent%','Oppo%',\n",
    "                   'Soft%','Med%','Hard%','O-Swing%','Z-Swing%','Swing%','O-Contact%','Z-Contact%',\n",
    "                   'Contact%','Zone%','F-Strike%','SwStr%','CStr%','CSW%','FBv','SL%','SLv','CT%',\n",
    "                   'CTv','CB%','CBv','CH%','CHv','SF%','SFv','KN%','KNv','XX%','wFB','wSL','wCT',\n",
    "                   'wCB','wCH','wSF','wKN','wFB/C','wSL/C','wCT/C','wCB/C','wCH/C','wSF/C','wKN/C', \n",
    "                   'W_x', 'SO', 'Sum_of_ERA_WHIP']\n",
    "\n",
    "    train_data_chosen_cols = train_dataset[chosen_cols]\n",
    "    test_data_chosen_cols = test_dataset[chosen_cols]\n",
    "\n",
    "    # Remove % signs\n",
    "    train_data_chosen_cols = train_data_chosen_cols.replace('%','', regex=True)\n",
    "    test_data_chosen_cols = test_data_chosen_cols.replace('%','', regex=True)\n",
    "\n",
    "    # Convert cols to floats\n",
    "    train_data_chosen_cols.astype(np.float64)\n",
    "    test_data_chosen_cols.astype(np.float64)\n",
    "\n",
    "    #starter_targets = ['W_x', 'SO', 'Sum_of_ERA_WHIP']\n",
    "    starter_targets = ['Sum_of_ERA_WHIP']\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    \n",
    "    train_data_x = train_data_chosen_cols.drop(starter_targets, axis=1)\n",
    "    test_data_x = test_data_chosen_cols.drop(starter_targets, axis=1)\n",
    "\n",
    "    for target in starter_targets:\n",
    "        train_data_y = train_data_chosen_cols[target]\n",
    "        test_data_y = test_data_chosen_cols[target]\n",
    "        # Scale x variable datasets\n",
    "        scaler = MinMaxScaler()\n",
    "        train_data_x_scaled = scaler.fit_transform(train_data_x)\n",
    "        test_data_x_scaled = scaler.fit_transform(test_data_x)\n",
    "\n",
    "        # ML Model using using fit and predict QB Fantasy Points\n",
    "        model = model_obj\n",
    "        model_name = type(model).__name__\n",
    "        print('Predict Starting Pitchers with a '+ model_name + ' model')\n",
    "        if (model_name == 'LinearRegression') or (model_name == 'Ridge'):\n",
    "            model = model.fit(train_data_x_scaled,train_data_y)\n",
    "        else:\n",
    "            model = model.fit(train_data_x_scaled,train_data_y.values.ravel())\n",
    "        y_preds = model.predict(test_data_x_scaled)\n",
    "        \n",
    "        mean_sq_err = None\n",
    "        r2_err = None\n",
    "        if year_to_project == 2023:\n",
    "            pass\n",
    "        else:\n",
    "            # The mean squared error\n",
    "            mean_sq_err = mean_squared_error(test_data_y, y_preds)\n",
    "            #print(\"Mean squared error: %.2f\" % mean_sq_err)\n",
    "            \n",
    "            # The mean absolute error\n",
    "            mean_ab_err = mean_squared_error(test_data_y, y_preds)\n",
    "\n",
    "            # The coefficient of determination: 1 is perfect prediction\n",
    "            r2_err = r2_score(test_data_y.values.ravel(), y_preds)\n",
    "\n",
    "        # Create new dataframe for projections\n",
    "        player_point_proj = None\n",
    "        proj_col_name  = 'Model_Projection_'+target\n",
    "        actuals_col_name  = 'Actual_'+target\n",
    "        if (model_name == 'LinearRegression') or (model_name == 'Ridge'):\n",
    "            #player_point_proj = pd.DataFrame({'Age': test_data_x['Age'], 'SLG': test_data_x['SLG'], proj_col_name: y_preds[:,0], actuals_col_name: test_data_y[target]})\n",
    "            player_point_proj = pd.DataFrame({'K/9_x': test_data_x['K/9_x'], 'BABIP': test_data_x['BABIP'], proj_col_name: y_preds, actuals_col_name: test_data_y})\n",
    "        else:\n",
    "            player_point_proj = pd.DataFrame({'K/9_x': test_data_x['K/9_x'], 'BABIP': test_data_x['BABIP'], proj_col_name: y_preds, actuals_col_name: test_data_y})\n",
    "        # Merge player names and info back in\n",
    "        #player_point_proj_wnames = player_point_proj.merge(master_df[['Player', 'Age', 'Position', 'Year', join_column, 'Fantasy_PPR']], how='inner', left_on=['Age', join_column, 'Actual_Points'], right_on=['Age', join_column, 'Fantasy_PPR'])\n",
    "\n",
    "        player_point_proj_wnames = player_point_proj.merge(test_dataset[['Name', 'K/9_x', 'BABIP', target]], how='inner', on=['K/9_x', 'BABIP'])\n",
    "        player_point_proj_wnames = player_point_proj_wnames.drop(columns=[target])\n",
    "\n",
    "        # Calculate Model vs Actual Delta\n",
    "        player_point_proj_wnames['Model_v_Actual_Delta'] = player_point_proj_wnames[proj_col_name] - player_point_proj_wnames[actuals_col_name]\n",
    "\n",
    "        # Prep Dataframe for csv output\n",
    "        player_point_proj_wnames = player_point_proj_wnames.sort_values(by=proj_col_name, ascending=False)\n",
    "        player_point_proj_wnames = player_point_proj_wnames[['Name', 'K/9_x', proj_col_name, actuals_col_name, 'Model_v_Actual_Delta']]\n",
    "        # Save dataframes\n",
    "        if year_to_project == 2023:\n",
    "            import time\n",
    "            timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            df = player_point_proj_wnames\n",
    "            adp = pd.read_csv('data/FantasyPros_2023_Overall_MLB_ADP_Rankings.csv')\n",
    "            adp = adp.rename({'Player': 'Name'}, axis=1)\n",
    "            df_w_adp = df.merge(adp, how='left', on='Name')\n",
    "            df_w_adp = df_w_adp.rename({'AVG': 'ADP'}, axis=1)\n",
    "            df_w_adp = df_w_adp[['Name',proj_col_name, actuals_col_name,'ADP']]\n",
    "            df_w_adp = df_w_adp.sort_values(by=proj_col_name)\n",
    "            df_w_adp = df_w_adp.drop_duplicates()\n",
    "            #filename = 'projections/'+str(position)+'/'+str(model_name)+'2022_projections_'+timestr+'.csv'\n",
    "            filename = 'projections/pitchers/starters/'+str(model_name)+'2023_projections_'+timestr+'.csv'\n",
    "            df_w_adp.to_csv(filename)\n",
    "        else:\n",
    "            return model_name, mean_sq_err, mean_ab_err, r2_err\n",
    "        \n",
    "\n",
    "def fantasy_points_predictor(models, year_to_project, train_dataset, test_dataset):\n",
    "    import time\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    results = []\n",
    "    for model in models:\n",
    "        model_name, mean_sq_err, mean_ab_err, r2_err = predict_starting_pitchers(model, year_to_project, train_dataset, test_dataset)\n",
    "        result = [model_name, mean_sq_err, mean_ab_err, r2_err]\n",
    "        results.append(result)\n",
    "            #position_projs_df.append(result)\n",
    "        #avg_position_projs = position_projs_df.groupby('Player')\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['Model Name', 'Mean Square Error', 'Mean Absolute Error', 'R2 Score'])\n",
    "    results_df = results_df.sort_values(by=['Mean Absolute Error'], ascending=[False])\n",
    "\n",
    "    top_sp_model = results_df.tail(1)\n",
    "    \n",
    "    if year_to_project == 2023:\n",
    "        print('Simulation complete! Check the projections folder to find your ranked players by position for this years draft.')\n",
    "    else:\n",
    "        results_filename = 'projections/pitchers/starters/2023_model_results_summary_'+timestr+'.csv'\n",
    "        results_df.to_csv(results_filename)\n",
    "        top_model_filename = 'projections/pitchers/starters/2023_top_models_by_position_summary_'+timestr+'.csv'\n",
    "        top_sp_model.to_csv(top_model_filename)\n",
    "        print('Simulation complete! Check the predictor_tool_results folder to find summary of models.')\n",
    "        return top_sp_model\n",
    "\n",
    "def model_object_generator(model_name):\n",
    "    if model_name == 'LinearRegression':\n",
    "        return LinearRegression()\n",
    "    elif model_name == 'Ridge':\n",
    "        return Ridge()\n",
    "    elif model_name == 'Lasso':\n",
    "        return Lasso()\n",
    "    elif model_name == 'BayesianRidge':\n",
    "        return BayesianRidge()\n",
    "    elif model_name == 'RandomForestRegressor':\n",
    "        #return RandomForestRegressor(n_estimators=1000, min_samples_leaf=4, min_samples_split=10)\n",
    "        return RandomForestRegressor(n_estimators=1000)\n",
    "    elif model_name == 'KNeighborsRegressor':\n",
    "        return KNeighborsRegressor()\n",
    "    elif model_name == 'MLPRegressor':\n",
    "        return MLPRegressor()\n",
    "    elif model_name == 'Elastic_Net':\n",
    "        return ElasticNet()\n",
    "    else:\n",
    "        print('Model not supported by model_object_generator function at the moment.')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Starting Pitchers with a LinearRegression model\n",
      "Predict Starting Pitchers with a Ridge model\n",
      "Predict Starting Pitchers with a Lasso model\n",
      "Predict Starting Pitchers with a BayesianRidge model\n",
      "Predict Starting Pitchers with a ElasticNet model\n",
      "Predict Starting Pitchers with a RandomForestRegressor model\n",
      "Predict Starting Pitchers with a KNeighborsRegressor model\n",
      "Predict Starting Pitchers with a MLPRegressor model\n",
      "Simulation complete! Check the predictor_tool_results folder to find summary of models.\n"
     ]
    }
   ],
   "source": [
    "models_list = [LinearRegression(), Ridge(), Lasso(), BayesianRidge(), ElasticNet(), RandomForestRegressor(), KNeighborsRegressor(), MLPRegressor(max_iter=1000)]\n",
    "train_dataset_2022 = pd.read_csv('data/fangraphs/pitchers/starters/pitchers_sp_19_21.csv')\n",
    "test_dataset_2022 = pd.read_csv('data/fangraphs/pitchers/starters/pitchers_sp_22.csv')\n",
    "\n",
    "top_sp_models = fantasy_points_predictor(models_list, 2022, train_dataset_2022, test_dataset_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>0.423929</td>\n",
       "      <td>0.423929</td>\n",
       "      <td>0.681401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Name  Mean Square Error  Mean Absolute Error  R2 Score\n",
       "7  MLPRegressor           0.423929             0.423929  0.681401"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_sp_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Starting Pitchers with a MLPRegressor model\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('data/fangraphs/pitchers/starters/pitchers_sp_19_21.csv')\n",
    "test_dataset = pd.read_csv('data/fangraphs/pitchers/starters/pitchers_sp_20_22.csv')\n",
    "\n",
    "predict_starting_pitchers(MLPRegressor(max_iter=1000), 2023, train_dataset, test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relievers Projection Building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_relief_pitchers(model_obj, proj_method, year_to_project, train_dataset, test_dataset):\n",
    "\n",
    "    # Preprocess the data and select features for the model\n",
    "\n",
    "    train_dataset = train_dataset.fillna(0)\n",
    "    test_dataset = test_dataset.fillna(0)\n",
    "\n",
    "    chosen_cols = []\n",
    "    starter_targets = []\n",
    "    if proj_method == \"W+SV+HLD\":\n",
    "        train_dataset['Sum_of_W_SV_HLD'] = train_dataset['W_x'] + train_dataset['SV_y'] + train_dataset['HLD']\n",
    "        test_dataset['Sum_of_W_SV_HLD'] = test_dataset['W_x'] + test_dataset['SV_y'] + test_dataset['HLD']\n",
    "\n",
    "        chosen_cols = ['K/9_x','BB/9_x','HR/9_x','BABIP_x','LOB%_x','GB%_x','HR/FB_x','vFA (pi)',\n",
    "                        'FIP_x','xFIP_x','CG','ShO','BS','K%','BB%','K-BB%','AVG', 'FIP-', 'xFIP-', \n",
    "                        'E-F',\t'BABIP', 'GB/FB', 'LD%','FB%_x','IFFB%','RS/9','Pull%','Cent%','Oppo%',\n",
    "                        'Soft%','Med%','Hard%','O-Swing%','Z-Swing%','Swing%','O-Contact%','Z-Contact%',\n",
    "                        'Contact%','Zone%','F-Strike%','SwStr%','CStr%','CSW%','FBv','SL%','SLv','CT%',\n",
    "                        'CTv','CB%','CBv','CH%','CHv','SF%','SFv','KN%','KNv','XX%','wFB','wSL','wCT',\n",
    "                        'wCB','wCH','wSF','wKN','wFB/C','wSL/C','wCT/C','wCB/C','wCH/C','wSF/C','wKN/C', \n",
    "                        'W_x', 'SO', 'Sum_of_W_SV_HLD']  \n",
    "        starter_targets = ['Sum_of_W_SV_HLD']\n",
    "    \n",
    "    elif proj_method == \"ERA+WHIP\":\n",
    "        train_dataset['Sum_of_ERA_WHIP'] = train_dataset['ERA_x'] + train_dataset['WHIP']\n",
    "        test_dataset['Sum_of_ERA_WHIP'] = test_dataset['ERA_x'] + test_dataset['WHIP']\n",
    "\n",
    "        chosen_cols = ['K/9_x','BB/9_x','HR/9_x','BABIP_x','LOB%_x','GB%_x','HR/FB_x','vFA (pi)',\n",
    "                        'FIP_x','xFIP_x','CG','ShO','BS','K%','BB%','K-BB%','AVG', 'FIP-', 'xFIP-', \n",
    "                        'E-F',\t'BABIP', 'GB/FB', 'LD%','FB%_x','IFFB%','RS/9','Pull%','Cent%','Oppo%',\n",
    "                        'Soft%','Med%','Hard%','O-Swing%','Z-Swing%','Swing%','O-Contact%','Z-Contact%',\n",
    "                        'Contact%','Zone%','F-Strike%','SwStr%','CStr%','CSW%','FBv','SL%','SLv','CT%',\n",
    "                        'CTv','CB%','CBv','CH%','CHv','SF%','SFv','KN%','KNv','XX%','wFB','wSL','wCT',\n",
    "                        'wCB','wCH','wSF','wKN','wFB/C','wSL/C','wCT/C','wCB/C','wCH/C','wSF/C','wKN/C', \n",
    "                        'W_x', 'SO', 'Sum_of_ERA_WHIP']  \n",
    "        starter_targets = ['Sum_of_ERA_WHIP']\n",
    "\n",
    "\n",
    "    train_data_chosen_cols = train_dataset[chosen_cols]\n",
    "    test_data_chosen_cols = test_dataset[chosen_cols]\n",
    "\n",
    "    # Remove % signs\n",
    "    train_data_chosen_cols = train_data_chosen_cols.replace('%','', regex=True)\n",
    "    test_data_chosen_cols = test_data_chosen_cols.replace('%','', regex=True)\n",
    "\n",
    "    # Convert cols to floats\n",
    "    train_data_chosen_cols.astype(np.float64)\n",
    "    test_data_chosen_cols.astype(np.float64)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    \n",
    "    train_data_x = train_data_chosen_cols.drop(starter_targets, axis=1)\n",
    "    test_data_x = test_data_chosen_cols.drop(starter_targets, axis=1)\n",
    "\n",
    "    for target in starter_targets:\n",
    "        train_data_y = train_data_chosen_cols[target]\n",
    "        test_data_y = test_data_chosen_cols[target]\n",
    "        # Scale x variable datasets\n",
    "        scaler = MinMaxScaler()\n",
    "        train_data_x_scaled = scaler.fit_transform(train_data_x)\n",
    "        test_data_x_scaled = scaler.fit_transform(test_data_x)\n",
    "\n",
    "        # ML Model using using fit and predict QB Fantasy Points\n",
    "        model = model_obj\n",
    "        model_name = type(model).__name__\n",
    "        print('Predict Relief Pitchers targeting ' + proj_method + ' with a '+ model_name + ' model')\n",
    "        if (model_name == 'LinearRegression') or (model_name == 'Ridge'):\n",
    "            model = model.fit(train_data_x_scaled,train_data_y)\n",
    "        else:\n",
    "            model = model.fit(train_data_x_scaled,train_data_y.values.ravel())\n",
    "        y_preds = model.predict(test_data_x_scaled)\n",
    "        \n",
    "        mean_sq_err = None\n",
    "        r2_err = None\n",
    "        if year_to_project == 2023:\n",
    "            pass\n",
    "        else:\n",
    "            # The mean squared error\n",
    "            mean_sq_err = mean_squared_error(test_data_y, y_preds)\n",
    "            #print(\"Mean squared error: %.2f\" % mean_sq_err)\n",
    "            \n",
    "            # The mean absolute error\n",
    "            mean_ab_err = mean_squared_error(test_data_y, y_preds)\n",
    "\n",
    "            # The coefficient of determination: 1 is perfect prediction\n",
    "            r2_err = r2_score(test_data_y.values.ravel(), y_preds)\n",
    "\n",
    "        # Create new dataframe for projections\n",
    "        player_point_proj = None\n",
    "        proj_col_name  = 'Model_Projection_'+target\n",
    "        actuals_col_name  = 'Actual_'+target\n",
    "        if (model_name == 'LinearRegression') or (model_name == 'Ridge'):\n",
    "            #player_point_proj = pd.DataFrame({'Age': test_data_x['Age'], 'SLG': test_data_x['SLG'], proj_col_name: y_preds[:,0], actuals_col_name: test_data_y[target]})\n",
    "            player_point_proj = pd.DataFrame({'K/9_x': test_data_x['K/9_x'], 'BABIP': test_data_x['BABIP'], proj_col_name: y_preds, actuals_col_name: test_data_y})\n",
    "        else:\n",
    "            player_point_proj = pd.DataFrame({'K/9_x': test_data_x['K/9_x'], 'BABIP': test_data_x['BABIP'], proj_col_name: y_preds, actuals_col_name: test_data_y})\n",
    "        # Merge player names and info back in\n",
    "        #player_point_proj_wnames = player_point_proj.merge(master_df[['Player', 'Age', 'Position', 'Year', join_column, 'Fantasy_PPR']], how='inner', left_on=['Age', join_column, 'Actual_Points'], right_on=['Age', join_column, 'Fantasy_PPR'])\n",
    "\n",
    "        player_point_proj_wnames = player_point_proj.merge(test_dataset[['Name', 'K/9_x', 'BABIP', target]], how='inner', on=['K/9_x', 'BABIP'])\n",
    "        player_point_proj_wnames = player_point_proj_wnames.drop(columns=[target])\n",
    "\n",
    "        # Calculate Model vs Actual Delta\n",
    "        player_point_proj_wnames['Model_v_Actual_Delta'] = player_point_proj_wnames[proj_col_name] - player_point_proj_wnames[actuals_col_name]\n",
    "\n",
    "        # Prep Dataframe for csv output\n",
    "        player_point_proj_wnames = player_point_proj_wnames.sort_values(by=proj_col_name, ascending=False)\n",
    "        player_point_proj_wnames = player_point_proj_wnames[['Name', 'K/9_x', proj_col_name, actuals_col_name, 'Model_v_Actual_Delta']]\n",
    "        # Save dataframes\n",
    "        if year_to_project == 2023:\n",
    "            import time\n",
    "            timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            df = player_point_proj_wnames\n",
    "            adp = pd.read_csv('data/FantasyPros_2023_Overall_MLB_ADP_Rankings.csv')\n",
    "            adp = adp.rename({'Player': 'Name'}, axis=1)\n",
    "            df_w_adp = df.merge(adp, how='left', on='Name')\n",
    "            df_w_adp = df_w_adp.rename({'AVG': 'ADP'}, axis=1)\n",
    "            df_w_adp = df_w_adp[['Name',proj_col_name, actuals_col_name,'ADP']]\n",
    "            if proj_method == \"W+SV+HLD\":\n",
    "                df_w_adp = df_w_adp.drop_duplicates()\n",
    "                df_w_adp = df_w_adp.sort_values(by=proj_col_name, ascending=False)\n",
    "                df_w_adp = df_w_adp[df_w_adp['Name'] != 'Luis Garcia']\n",
    "                df_w_adp = df_w_adp[df_w_adp['Name'] != 'Javy Guerra']\n",
    "                df_w_adp = df_w_adp[df_w_adp['Name'] != 'Will Smith']\n",
    "                filename = 'projections/pitchers/relievers/'+str(model_name)+'2023_W_SV_HLD_projections_'+timestr+'.csv'\n",
    "                df_w_adp.to_csv(filename)\n",
    "            elif proj_method == \"ERA+WHIP\":\n",
    "                df_w_adp = df_w_adp.drop_duplicates()\n",
    "                df_w_adp = df_w_adp.sort_values(by=proj_col_name, ascending=True)\n",
    "                df_w_adp = df_w_adp[df_w_adp['Name'] != 'Luis Garcia']\n",
    "                df_w_adp = df_w_adp[df_w_adp['Name'] != 'Javy Guerra']\n",
    "                df_w_adp = df_w_adp[df_w_adp['Name'] != 'Will Smith']\n",
    "                filename = 'projections/pitchers/relievers/'+str(model_name)+'2023_ERA_WHIP_projections_'+timestr+'.csv'\n",
    "                df_w_adp.to_csv(filename)            \n",
    "            #filename = 'projections/'+str(position)+'/'+str(model_name)+'2022_projections_'+timestr+'.csv'\n",
    "\n",
    "        else:\n",
    "            return model_name, mean_sq_err, mean_ab_err, r2_err\n",
    "        \n",
    "\n",
    "def fantasy_points_predictor(models, proj_method, year_to_project, train_dataset, test_dataset):\n",
    "    import time\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    results = []\n",
    "    for model in models:\n",
    "        model_name, mean_sq_err, mean_ab_err, r2_err = predict_relief_pitchers(model, proj_method, year_to_project, train_dataset, test_dataset)\n",
    "        result = [model_name, mean_sq_err, mean_ab_err, r2_err]\n",
    "        results.append(result)\n",
    "            #position_projs_df.append(result)\n",
    "        #avg_position_projs = position_projs_df.groupby('Player')\n",
    "\n",
    "    results_df = pd.DataFrame(results, columns=['Model Name', 'Mean Square Error', 'Mean Absolute Error', 'R2 Score'])\n",
    "    results_df = results_df.sort_values(by=['Mean Absolute Error'])\n",
    "\n",
    "    top_rp_model = results_df.head(1)\n",
    "    \n",
    "    if year_to_project == 2023:\n",
    "        print('Simulation complete! Check the projections folder to find your ranked players by position for this years draft.')\n",
    "    else:\n",
    "        if proj_method == \"W+SV+HLD\":\n",
    "            results_filename = 'projections/pitchers/relievers/2023_model_results_W_SV_HLD_summary_'+timestr+'.csv'\n",
    "            results_df.to_csv(results_filename)\n",
    "            top_model_filename = 'projections/pitchers/relievers/2023_top_models_W_SV_HLD_by_position_summary_'+timestr+'.csv'\n",
    "            top_rp_model.to_csv(top_model_filename)\n",
    "        elif proj_method == \"ERA+WHIP\":\n",
    "            results_filename = 'projections/pitchers/relievers/2023_model_results_ERA_WHIP_summary_'+timestr+'.csv'\n",
    "            results_df.to_csv(results_filename)\n",
    "            top_model_filename = 'projections/pitchers/relievers/2023_top_models_ERA_WHIP_by_position_summary_'+timestr+'.csv'\n",
    "            top_rp_model.to_csv(top_model_filename)\n",
    "        print('Simulation complete! Check the predictor_tool_results folder to find summary of models.')\n",
    "        return top_rp_model\n",
    "\n",
    "def model_object_generator(model_name):\n",
    "    if model_name == 'LinearRegression':\n",
    "        return LinearRegression()\n",
    "    elif model_name == 'Ridge':\n",
    "        return Ridge()\n",
    "    elif model_name == 'Lasso':\n",
    "        return Lasso()\n",
    "    elif model_name == 'BayesianRidge':\n",
    "        return BayesianRidge()\n",
    "    elif model_name == 'RandomForestRegressor':\n",
    "        #return RandomForestRegressor(n_estimators=1000, min_samples_leaf=4, min_samples_split=10)\n",
    "        return RandomForestRegressor(n_estimators=1000)\n",
    "    elif model_name == 'KNeighborsRegressor':\n",
    "        return KNeighborsRegressor()\n",
    "    elif model_name == 'MLPRegressor':\n",
    "        return MLPRegressor()\n",
    "    elif model_name == 'Elastic_Net':\n",
    "        return ElasticNet()\n",
    "    else:\n",
    "        print('Model not supported by model_object_generator function at the moment.')\n",
    "        return None\n",
    "\n",
    "def combined_reliever_rankings(wsvhld_dataset, erawhip_dataset):\n",
    "    import time\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    #wsvhld_dataset = wsvhld_dataset.iloc[:,1:]\n",
    "    print(wsvhld_dataset.columns)\n",
    "    wsvhld_min = wsvhld_dataset['Model_Projection_Sum_of_W_SV_HLD'].min()\n",
    "    wsvhld_max = wsvhld_dataset['Model_Projection_Sum_of_W_SV_HLD'].max()\n",
    "    wsvhld_dataset['Scaled_WSVHLD_Rank'] = (wsvhld_dataset['Model_Projection_Sum_of_W_SV_HLD']-wsvhld_min)/(wsvhld_max-wsvhld_min)\n",
    "\n",
    "    #erawhip_dataset = wsvhld_dataset.iloc[:,1:]\n",
    "    erawhip_min = erawhip_dataset['Model_Projection_Sum_of_ERA_WHIP'].min()\n",
    "    erawhip_max = erawhip_dataset['Model_Projection_Sum_of_ERA_WHIP'].max()\n",
    "    erawhip_dataset['Scaled_ERAWHIP_Rank'] = 1-(erawhip_dataset['Model_Projection_Sum_of_ERA_WHIP']-erawhip_min)/(erawhip_max-erawhip_min)\n",
    "\n",
    "    ovr_rp_rankings = wsvhld_dataset.merge(erawhip_dataset, how='left', on='Name')\n",
    "    ovr_rp_rankings['Scaled_OVR_Score'] = (ovr_rp_rankings['Scaled_WSVHLD_Rank'] + ovr_rp_rankings['Scaled_ERAWHIP_Rank']) * 50\n",
    "    ovr_rp_rankings = ovr_rp_rankings.sort_values(by='Scaled_OVR_Score', ascending=False)\n",
    "    ovr_rp_rankings['OVR_Rank'] = np.arange(len(ovr_rp_rankings))+1\n",
    "    \n",
    "    ovr_rp_rankings_filename = 'projections/pitchers/relievers/2023_ovr_rp_rankings_'+timestr+'.csv'\n",
    "    ovr_rp_rankings.to_csv(ovr_rp_rankings_filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Relief Pitchers targeting W+SV+HLD with a LinearRegression model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a Ridge model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a Lasso model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a BayesianRidge model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a ElasticNet model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a RandomForestRegressor model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a KNeighborsRegressor model\n",
      "Predict Relief Pitchers targeting W+SV+HLD with a MLPRegressor model\n",
      "Simulation complete! Check the predictor_tool_results folder to find summary of models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models_list = [LinearRegression(), Ridge(), Lasso(), BayesianRidge(), ElasticNet(), RandomForestRegressor(), KNeighborsRegressor(), MLPRegressor(max_iter=1000)]\n",
    "train_dataset_2022 = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_19_21.csv')\n",
    "test_dataset_2022 = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_22.csv')\n",
    "\n",
    "top_rp_models_sv = fantasy_points_predictor(models_list, \"W+SV+HLD\", 2022, train_dataset_2022, test_dataset_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>54.9572</td>\n",
       "      <td>54.9572</td>\n",
       "      <td>0.516485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model Name  Mean Square Error  Mean Absolute Error  R2 Score\n",
       "7  MLPRegressor            54.9572              54.9572  0.516485"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rp_models_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Relief Pitchers targeting W+SV+HLD with a MLPRegressor model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mattg\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_19_21.csv')\n",
    "test_dataset = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_20_22.csv')\n",
    "\n",
    "predict_relief_pitchers(MLPRegressor(max_iter=1000), \"W+SV+HLD\", 2023, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Relief Pitchers targeting ERA+WHIP with a LinearRegression model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a Ridge model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a Lasso model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a BayesianRidge model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a ElasticNet model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a RandomForestRegressor model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a KNeighborsRegressor model\n",
      "Predict Relief Pitchers targeting ERA+WHIP with a MLPRegressor model\n",
      "Simulation complete! Check the predictor_tool_results folder to find summary of models.\n"
     ]
    }
   ],
   "source": [
    "models_list = [LinearRegression(), Ridge(), Lasso(), BayesianRidge(), ElasticNet(), RandomForestRegressor(), KNeighborsRegressor(), MLPRegressor(max_iter=1000)]\n",
    "train_dataset_2022 = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_19_21.csv')\n",
    "test_dataset_2022 = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_22.csv')\n",
    "\n",
    "top_rp_models_era = fantasy_points_predictor(models_list, \"ERA+WHIP\", 2022, train_dataset_2022, test_dataset_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Square Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.274435</td>\n",
       "      <td>1.274435</td>\n",
       "      <td>0.703104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Name  Mean Square Error  Mean Absolute Error  R2 Score\n",
       "1      Ridge           1.274435             1.274435  0.703104"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rp_models_era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Relief Pitchers targeting ERA+WHIP with a Ridge model\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_19_21.csv')\n",
    "test_dataset = pd.read_csv('data/fangraphs/pitchers/relievers/pitchers_rp_20_22.csv')\n",
    "\n",
    "predict_relief_pitchers(Ridge(), \"ERA+WHIP\", 2023, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Name', 'Model_Projection_Sum_of_W_SV_HLD',\n",
      "       'Actual_Sum_of_W_SV_HLD', 'ADP'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "wsvhld_dataset = pd.read_csv('projections/pitchers/relievers/MLPRegressor2023_W_SV_HLD_projections_20230312-163802.csv')\n",
    "erawhip_dataset = pd.read_csv('projections/pitchers/relievers/Ridge2023_ERA_WHIP_projections_20230312-163804.csv')\n",
    "combined_reliever_rankings(wsvhld_dataset, erawhip_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cd0033651e21e328f773e74c32896f0cbbc0d361abd5ec8e5e349eb776dcd6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
